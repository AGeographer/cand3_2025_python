{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMych20X0WBHbm2Mr5optZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AGeographer/cand3_2025_python/blob/main/CAnD3_ML_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><img src=\"https://www.mcgill.ca/cand3/files/cand3/cand3_logo_final_fullname.png\" width=\"150\">Introduction to Machine Learning with <img src=\"https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png\" width=\"30\"> <code>Python</code> for social scientific research </h1>\n",
        "<h3>Instructor: Dr. Tim Elrick, GIC, McGill (<a mailto=\"tim.elrick@mcgill.ca\">tim.elrick@mcgill.ca</a>)</h3>"
      ],
      "metadata": {
        "id": "GtfSmtMgcMkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation\n",
        "\n",
        "First, we prepare our notebook by loading relevant modules."
      ],
      "metadata": {
        "id": "fdr7oZQLeAhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy for working with data\n",
        "import numpy as np\n",
        "\n",
        "# pandas for data sets\n",
        "import pandas as pd\n",
        "\n",
        "# scikit-learn for machine learning\n",
        "# for preprocessing (normalizing data)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# for selecting models\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
        "\n",
        "# for model fitting\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "R0lAQY8BdrpU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we load the data set that we want to work on. Here, we use a data set on restaurants in New York City that contains *Michelin guide*-ratings (they are coming to Montreal this year!)."
      ],
      "metadata": {
        "id": "gF2ojdAtd_d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data set\n",
        "data = pd.read_csv(\"https://gattonweb.uky.edu/sheather/book/docs/datasets/MichelinNY.csv\",\n",
        "                   encoding ='latin-1')\n",
        "\n",
        "# Have a look at the data\n",
        "data.describe(include= 'all')"
      ],
      "metadata": {
        "id": "2x-bkuYd0gaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to use the unsupervised machine learning method *k-nearest neighbours* to find out if we can predict which restaurant is mentioned in the Michelin guide or not."
      ],
      "metadata": {
        "id": "pGoqpF2-fXMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We separate the predicted variable y and the predictor variables X (capital X for a vector of variables)\n",
        "\n",
        "y = data['InMichelin']\n",
        "\n",
        "X = data.drop(columns = ['InMichelin', 'Restaurant Name'])"
      ],
      "metadata": {
        "id": "hmev4lE2ekim"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-Validation\n",
        "\n",
        "Next, we'll split our sample into two disjoint sets: a **training set** featuring 80% of our observations; and a **testing set**—or *hold-out sample* comprising 20% of the original dataset—that will not be involved in the training or validation process. We'll also ensure that our feature vectors have been standardized.\n",
        "\n",
        "Then, we'll initialize our KNN and use (stratified) $k$-fold cross-validation to fit a basic KNN model."
      ],
      "metadata": {
        "id": "CRaGwdMvgLYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform train-test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    stratify = y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 905)"
      ],
      "metadata": {
        "id": "LbzqkXMD0gJu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing our data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# we use .fit_transform() on the training data (fitting means that we calculate average and standard deviation)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# we use .transform() on the test data (we don't want the test data to get a peek on the training data, that is called a data leakage)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Ljv59R7KhGmq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing KNN classifier for fitting the model. Here, we randomly choose k=5\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors = 5)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3gN-pV_N0f-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's use the k-fold cross-validation. We split the data set into 5 to 10 folds.\n",
        "# for smaller data sets you usually choose higher folds than for larger data sets.\n",
        "\n",
        "skfold = StratifiedKFold(n_splits = 10,\n",
        "                         shuffle = True,\n",
        "                         random_state = 905)"
      ],
      "metadata": {
        "id": "wPsL5L5b14Ix"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation scores for each fold (accuracy)\n",
        "\n",
        "scores = cross_val_score(model, X_train, y_train,\n",
        "                         cv = skfold)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "JFKYcqjAm3UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we get a high mean score, the model performs well."
      ],
      "metadata": {
        "id": "JIEePRVKmqu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# So, the average of all folds is\n",
        "\n",
        "scores.mean()"
      ],
      "metadata": {
        "id": "HcldKIi9lHav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's compare this to our actual model, when we use the **test data**. If the value is similar to the *cross-validation*, it's a good sign. If your model score is much higher than the cross-validation your model might be overfitted."
      ],
      "metadata": {
        "id": "5IcneFZ7mbFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure of predictive performance (accuracy of our model)\n",
        "\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "xEnd5H0wciXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Optimization\n",
        "\n",
        "Next, we'll use the `GridSearchCV` method to select the optimal value of $k$ by using a grid search of possible hyperparameter values (**Rule of thumb:** odd numbers between 1 and $\\sqrt{sample}$, here $\\sqrt164=13$)."
      ],
      "metadata": {
        "id": "rXfMs68vneup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a array/vector (in ML here called grid) of potential hyperparameter values (odd numbers from 1 to 13):\n",
        "\n",
        "k_grid = {'n_neighbors': np.arange(start = 1, stop = 15, step = 2) }\n",
        "\n",
        "print(k_grid)"
      ],
      "metadata": {
        "id": "7OGtEtd32LO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up a grid search to home-in on best value of k:\n",
        "\n",
        "grid = GridSearchCV(KNeighborsClassifier(), param_grid = k_grid, cv = skfold)\n",
        "\n",
        "print(grid)"
      ],
      "metadata": {
        "id": "UbNgtYAMnZfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we fit the grid models\n",
        "\n",
        "grid.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "h8NLokL3ngCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract best score and hyperparameter value:\n",
        "\n",
        "print(\"Best Mean Cross-Validation Score: {:.3f}\".format(grid.best_score_))\n",
        "\n",
        "print(\"Best Parameters (Value of k): {}\".format(grid.best_params_))\n",
        "\n",
        "print(\"Test Set Score: {:.3f}\".format(grid.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "DWI05NlQn0kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can look at the results as a data frame\n",
        "\n",
        "pd.DataFrame(grid.cv_results_).head()"
      ],
      "metadata": {
        "id": "EMyYwpMso--R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}