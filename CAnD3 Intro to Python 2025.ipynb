{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "9qU5JDB7jHPA",
        "uhkgdWLZi4Bq",
        "jW81cF0buf8E",
        "jlohWuMl6Y2F",
        "vS6BTpGk2oBt"
      ],
      "authorship_tag": "ABX9TyPFJJaZ689qR8pBme1zNe7R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><img src=\"https://www.mcgill.ca/cand3/files/cand3/cand3_logo_final_fullname.png\" width=\"150\">Introduction to <img src=\"https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/community/logos/python-logo-only.png\" width=\"30\"> <code>Python</code> for social scientific research </h1>\n",
        "<h3>Instructor: Dr. Tim Elrick, GIC, McGill (<a mailto=\"tim.elrick@mcgill.ca\">tim.elrick@mcgill.ca</a>)</h3>\n"
      ],
      "metadata": {
        "id": "YVYEqb6xkkTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prolog\n",
        "\n",
        "In the following you find an introduction to working with tabluar data (aka tables, data sets or data frames) in `Python`. As you have been working with `R` for quite a while, this notebook dives into the matter more swiftly than one usually would when starting out learning `Python`.\n",
        "\n",
        "In this workshop you will learn\n",
        "\n",
        "- how to work with functions, methods and attributes\n",
        "- how to load and use modules\n",
        "- how to import and export data\n",
        "- how to manipulate tabular data frames\n",
        "- create and visualize descriptive statistics\n",
        "\n",
        "For doing so, we draw on the modules [`numpy`](https://numpy.org/doc/stable/user/index.html) (for scientific computing), [`pandas`](https://pandas.pydata.org/docs/user_guide/index.html) (for working with tabluar data) and [`seaborn`](https://seaborn.pydata.org/tutorial.html) (for visualizing data easily).\n",
        "\n",
        "As `Python` is a more general programming language, this workshop **will not suffice** to provide you with an exhaustive overview or understanding of how `Python` works to properly use it for research in the social sciences.\n",
        "That said, we will further delve into `Python` in a couple of weeks to learn about how you can apply machine learning in this language using the module [`scikit-learn`](https://scikit-learn.org/stable/user_guide.html).\n"
      ],
      "metadata": {
        "id": "3Jq5JtNMZcgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Loading libraries\n",
        "Now, let's load our first libraries, which are called `module` in `Python`."
      ],
      "metadata": {
        "id": "SzjawXCjo0Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use canonical naming conventions (aliases) for our modules np, pd and\n",
        "# sns and the submodule plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "1eO-bE7BkjGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Loading data\n",
        "To load tabular data, we can use the different `read_*()` functions that are shipped with the module `pandas`.\n",
        "\n",
        "> Note, In `Python` functions from modules are called by invoking the name of the module first, followed by `.` (dot) and then the name of the function. These functions are then called `methods`."
      ],
      "metadata": {
        "id": "m8FStBsvgVds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We load the data from Tim's GitHub repository (you might recall the migration\n",
        "# data from the R summer camp)\n",
        "# Data source:\n",
        "#   Statistics Canada 2017: Estimates of the components of interprovincial\n",
        "#                             migration, quarterly\n",
        "#   https://doi.org/10.25318/1710002001-eng\n",
        "\n",
        "data_csv = pd.read_csv('https://github.com/AGeographer/cand3_2025_python/raw/refs/heads/main/data/migration.csv')"
      ],
      "metadata": {
        "id": "5yyPWpI9gU0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv"
      ],
      "metadata": {
        "id": "dDnfANGy94yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objects also can have functions/methods. E.g. `head()` allows you to see the first rows of a data set."
      ],
      "metadata": {
        "id": "JdgT1zIplmA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_csv.head()"
      ],
      "metadata": {
        "id": "6PTheB2Uki9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to load a dta (Stata) data set, use\n",
        "\n",
        "data_dta = pd.read_stata('https://github.com/AGeographer/cand3_2025_python/raw/refs/heads/main/data/migration.dta')"
      ],
      "metadata": {
        "id": "8S9SIjINkiqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's check if both data sets are the same. For doing so we can use the usual `logical operators`:"
      ],
      "metadata": {
        "id": "ERGtF6tenGwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dta == data_csv"
      ],
      "metadata": {
        "id": "HZ6daDF3musC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### *Exercise 1*\n",
        "\n",
        "Load the `Excel` data from the repository.\n",
        "\n",
        "> Expand the solution to check your results.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ulLRpIQenY8C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8vGiT3njIyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Solution for exercise 1\n"
      ],
      "metadata": {
        "id": "9qU5JDB7jHPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For `Excel` data sets, we can (or need) to specify the sheet and if it should skip certain rows."
      ],
      "metadata": {
        "id": "on_qR2VwoP_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_excel = pd.read_excel('https://github.com/AGeographer/cand3_2025_python/raw/refs/heads/main/data/migration.xlsx')"
      ],
      "metadata": {
        "id": "FIjw4oywwe3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_excel.head()"
      ],
      "metadata": {
        "id": "IULMBwVqq9dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_excel = pd.read_excel('https://github.com/AGeographer/cand3_2025_python/raw/refs/heads/main/data/migration.xlsx',\n",
        "                           skiprows=1)\n",
        "\n",
        "# if you want to learn more about a function/method, use ? followed by the function name\n",
        "\n",
        "?pd.read_excel"
      ],
      "metadata": {
        "id": "CGcn2mVcnoq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_excel.head()"
      ],
      "metadata": {
        "id": "sUZi51Din6Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Continuing ..."
      ],
      "metadata": {
        "id": "PKRAKuHXkUPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: there are many more `read_*()` functions. You can check these out by typing `pd.`, then wait shortly until the drop-down opens, then you can scroll through all the *`pd` methods*."
      ],
      "metadata": {
        "id": "aLLbzrM_xeTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Exploring data\n",
        "\n",
        "Let's shorten the name of our data set, by using method `.copy()`.\n",
        "\n",
        "> Note: if we just used `ds=data_csv` it would just created an *alias*, i.e. it would be the same object with a different name. This is a notable difference between `Python` and `R`."
      ],
      "metadata": {
        "id": "zZsaxK8fyga3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = data_csv.copy()"
      ],
      "metadata": {
        "id": "CSWS2qRFxPBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3.1) Getting an overview\n",
        "\n",
        "Now, we can explore the data set:"
      ],
      "metadata": {
        "id": "JcBSAJvty2NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get a comprehensive overview over the structure of the data set\n",
        "\n",
        "ds.info()"
      ],
      "metadata": {
        "id": "WlIk826vy9S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to get a list of all the columns/variables\n",
        "\n",
        "ds.columns"
      ],
      "metadata": {
        "id": "z6LR6i-xzIVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# where there is\n",
        "\n",
        "ds.head()\n",
        "\n",
        "# ... there is also\n",
        "\n",
        "ds.tail(3)"
      ],
      "metadata": {
        "id": "DYo_2PObzUtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note, a `Notebook code cell` is executed in total and only displays the last output (if there is output)."
      ],
      "metadata": {
        "id": "PAQUqp-Bzc6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to see all output you need to wrap the code in print()\n",
        "\n",
        "print(ds.head(2))\n",
        "print(ds.head(2))"
      ],
      "metadata": {
        "id": "KixjMZ5ezuh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to get the dimensions of a data set, use\n",
        "\n",
        "ds.shape"
      ],
      "metadata": {
        "id": "5gUIp0Qo0EVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the different variable types, use\n",
        "\n",
        "ds.dtypes"
      ],
      "metadata": {
        "id": "l-R3B27M1Qm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In `pandas` the most common *variable types* are:\n",
        "\n",
        "- `object`: Used for strings (text) or mixed data types within a column.\n",
        "- `int64`: Represents integers (whole numbers).\n",
        "- `float64`: Represents floating-point numbers (numbers with decimals).\n",
        "- `bool`: Represents boolean values (`True` or `False`).\n",
        "- `datetime64`: Represents dates and times.\n",
        "- `timedelta[ns]`: Represents the difference between two datetimes.\n",
        "- `category`: Used for categorical data, which can improve performance and memory usage.\n",
        "\n",
        "> Note: although, `pandas` are built on `numpy` arrays (i.e. *vectors*) the *variable types* differ between the two modules."
      ],
      "metadata": {
        "id": "pCIaMh_F12jE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2) Exploring the data visually\n",
        "\n",
        "We can use the `seaborn` module to explore the data set visually:"
      ],
      "metadata": {
        "id": "dy-ogx613mRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme()\n",
        "sns.pairplot(ds)"
      ],
      "metadata": {
        "id": "mlHUaF_Z3ljt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as you see, sns.pairplot() only uses the numerical columns to display the\n",
        "# plot. You can use a categorical variable/column to colour the plot\n",
        "\n",
        "sns.pairplot(ds, hue='GEO')"
      ],
      "metadata": {
        "id": "q5BB3yyB4UkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3) Exploring data with descriptive statistics"
      ],
      "metadata": {
        "id": "UaP50QdN95S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.describe()"
      ],
      "metadata": {
        "id": "YHEqapuG92AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to also include the categorical variables\n",
        "\n",
        "ds.describe(include='all')"
      ],
      "metadata": {
        "id": "5_7LdDcp-Yli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to include only a certain variable type\n",
        "\n",
        "ds.describe(include=['object'])"
      ],
      "metadata": {
        "id": "KIo0ZRcb_Z3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we are interested in a certain column, we can call it with\n",
        "\n",
        "ds['GEO']"
      ],
      "metadata": {
        "id": "Cq-sV8wFACKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or use the notion that columns in a data set are represented as attributes\n",
        "\n",
        "ds.GEO"
      ],
      "metadata": {
        "id": "aFmxuXCd_ooo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to get the unique values of a variable\n",
        "\n",
        "ds.GEO.unique()"
      ],
      "metadata": {
        "id": "4LQfAO8A_uC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to get the count of a variable by unique values\n",
        "ds.GEO.value_counts()"
      ],
      "metadata": {
        "id": "BsGNr0sWAqZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we get relative value by\n",
        "\n",
        "ds.GEO.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "SD-rswasAxSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Python` is an *object-oriented* language, i.e. everything acts as an *object*:"
      ],
      "metadata": {
        "id": "7oX3da2sBHWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.GEO.value_counts(normalize=True).round(2)"
      ],
      "metadata": {
        "id": "yGsoZSwkBEef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can wrap an equation in parentheses and then work with this new object\n",
        "\n",
        "(ds.GEO.value_counts(normalize=True) * 100).round(2)"
      ],
      "metadata": {
        "id": "RWBo_lHBBZB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can extend this to\n",
        "\n",
        "(ds.GEO.value_counts(normalize=True) * 100).round(2).plot(kind='bar')\n",
        "\n",
        "# ... a basic matplotlib (plt) bar plot"
      ],
      "metadata": {
        "id": "X3cMZ56LCDLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and, calling the count like this, works as well, of course\n",
        "\n",
        "ds['GEO'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "IYPK0fj1Cqql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by the way,\n",
        "\n",
        "ds.GEO.count()\n",
        "\n",
        "# returns the full number of rows"
      ],
      "metadata": {
        "id": "8M-YHVnqBAYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single descriptive stats are possible to calculate as well, of course. E.g. we can calcuate the average\n",
        "with the `mean()` function."
      ],
      "metadata": {
        "id": "H5tO97lRC93c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's start with describe() again\n",
        "\n",
        "ds.describe()"
      ],
      "metadata": {
        "id": "1arpPfDhB_aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.mean()\n",
        "\n",
        "# here we will get a TypeError, as the function tries to calculate the mean\n",
        "# on the wrong (variable) type, i.e. strings"
      ],
      "metadata": {
        "id": "KL5qVtGUDYjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so, either, we calculate the mean only on one numeric column\n",
        "\n",
        "ds.Value.mean().round(2)"
      ],
      "metadata": {
        "id": "txEAz2jWDFjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### *Exercise 2*\n",
        "\n",
        "Calculate the minimum and the median for the migration value.\n",
        "\n",
        "> Expand the solution to check your results.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "EqQjTfIKJj20"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0dBZiP7zi070"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Solution for exercise 2\n"
      ],
      "metadata": {
        "id": "uhkgdWLZi4Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.Value.min()"
      ],
      "metadata": {
        "id": "7LWQBVmdJytc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['Value'].median()"
      ],
      "metadata": {
        "id": "3Fb2-FdfJUli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to know which row contains the smallest population, use\n",
        "\n",
        "ds.nsmallest(n=1, columns='Value')"
      ],
      "metadata": {
        "id": "w0TZKHmqkBq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Continuing ..."
      ],
      "metadata": {
        "id": "HU7f7LVakZd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coming back to how to calculate the mean...\n",
        "# or we tell the function to only use numeric variables in the data set\n",
        "\n",
        "ds.mean(numeric_only=True)"
      ],
      "metadata": {
        "id": "oZU-HwpoDUM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Side-track: How to create a `function`\n",
        "\n",
        "Due to the big number in variable `population` the `mean()` function decided to output the numbers in *scientific notation*. If you want to override this behaviour, you have to use the `apply()` method together with a *format function*, called `f''`.\n",
        "\n",
        "Now, there are two ways of defining functions:\n",
        "\n",
        "1. a `lambda` function on the fly\n",
        "2. a permanent function"
      ],
      "metadata": {
        "id": "WCuQ9zqtEwWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a lambda function starts with the word lambda and then the variable you want\n",
        "# to use, e.g. x:\n",
        "# lambda x: x * 2\n",
        "# after the colon you define what the function should do, e.g.\n",
        "\n",
        "ds.mean(numeric_only=True).apply(lambda x: round(x, 2))"
      ],
      "metadata": {
        "id": "R8BhyCHjGWQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, the numbers are better readable, but not yet ideal\n",
        "# let's look at f''\n",
        "\n",
        "f'{10000:,.2f}'\n",
        "\n",
        "# f'' is a string that contains variables in {}\n",
        "# you can then format this string, hence f''\n",
        "# after the variable you add a colon : and then specify e.g. the number format\n",
        "# ,.2f formats a float to a number with thousand separator and 2 digits"
      ],
      "metadata": {
        "id": "7EOkkXPPG_Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we can combine\n",
        "\n",
        "ds.mean(numeric_only=True).apply(lambda x: f'{x:,.1f}')"
      ],
      "metadata": {
        "id": "hDoYSrriFiuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternatively, we can define a new function permanently, by using\n",
        "\n",
        "def format_number(x):\n",
        "    return f'{x:,.3f}'\n",
        "\n",
        "# you can call the function anything, here we called it format_number()\n",
        "# note, that after the definition you need to use a colon, and then the next\n",
        "# line needs to be indented, otherwise the function will not work.\n",
        "\n",
        "# after defining the function we can use in the apply() method\n",
        "\n",
        "ds.mean(numeric_only=True).apply(format_number)"
      ],
      "metadata": {
        "id": "cfJ_H6RmEm0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's revisit the relative count\n",
        "\n",
        "# now, let's turn the output in percentages with a lambda function\n",
        "\n",
        "ds.GEO.value_counts(normalize=True).apply(lambda x: f'{x:.0%}')"
      ],
      "metadata": {
        "id": "L5o9hBsKH8ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuing with calculating statistics:\n",
        "\n",
        "`mean(numeric_only=True)` is not the only way to achieve this."
      ],
      "metadata": {
        "id": "m6AZcQPVmQtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can also either include certain variable types\n",
        "\n",
        "ds.select_dtypes(include='number').mean()"
      ],
      "metadata": {
        "id": "bnsTge5ln5Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or exclude them\n",
        "\n",
        "ds.select_dtypes(exclude='object').mean()"
      ],
      "metadata": {
        "id": "pj2yoGgAoE4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Subsetting data"
      ],
      "metadata": {
        "id": "lGCFy3sHoSPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can store subsets in a new object\n",
        "\n",
        "ds15 = ds.tail(15)"
      ],
      "metadata": {
        "id": "vk4rIKrrpPSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds15"
      ],
      "metadata": {
        "id": "QkRaktnjpg_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deleting columns\n",
        "\n",
        "In the method `.drop()` you can specify the columns that you want to delete.\n",
        "\n",
        "> Note, when you set `inplace=True` it will create a copy right away (equivalent to an *left assignment* in `R`)."
      ],
      "metadata": {
        "id": "4o4Ct1xpL5oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.drop(columns=['Vector','Coordinate'], inplace=True)"
      ],
      "metadata": {
        "id": "RWpLWhmGKF8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can check if it was successful\n",
        "\n",
        "ds"
      ],
      "metadata": {
        "id": "R1mEYM8KLxq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renaming columns\n",
        "\n",
        "Use method `.rename` to rename columns by creating a `dictionary` which is a crucial *data type* in `Python`.\n",
        "\n",
        "A `dictionary` consists of a *key-value structure*, each entry separated by comma and written like this: `{'key1':'value1', 'key2':'value2'}`."
      ],
      "metadata": {
        "id": "YfmopAwXMkiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_dictionary = {'fruit': 'apple', 'vegetable': 'carrot'}\n",
        "a_dictionary"
      ],
      "metadata": {
        "id": "JnZMdJY-Owma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this knowledge on `.rename()` for a data set, the `key` is the *old column name* and the `value` is the *new column name*."
      ],
      "metadata": {
        "id": "PqnE_o4APYYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you don't use inplace=True you need to assign the code to your data set\n",
        "\n",
        "ds = ds.rename(columns={'GEO':'Location', 'INT':'Type', 'Value':'Persons'})"
      ],
      "metadata": {
        "id": "k_xik3ibKL9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "HAr6925AN6Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subsetting through a condition on row values\n",
        "\n",
        "Use method `.query('')` to create *logical expressions* to filter rows.\n",
        "\n",
        "> Note: `inplace=True` works on `.query` as well."
      ],
      "metadata": {
        "id": "gbhU-mJlQmWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.query('Location != \"Canada\"')"
      ],
      "metadata": {
        "id": "qJ8f1D4rQue8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to reset the index of the data set, i.e. the rownames, use\n",
        "\n",
        "ds = ds.query('Location != \"Canada\"').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "CP5tFt5dRjn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method `.loc` allows you to subset to certain ranges of rows and columns by *row numbers* and *variable name(s)*. If the rows have an named `index` then you also can select by those names (not in our case here),\n"
      ],
      "metadata": {
        "id": "-VBztY8vqPDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we always enter rows, columns\n",
        "# So, here we want row 1 to 10\n",
        "# and columns country to lifeExp.\n",
        "\n",
        "ds.loc[1:10, 'Location':'Persons']"
      ],
      "metadata": {
        "id": "6L0pAwYFpm9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note, Python starts counting at 0. So, the first row is\n",
        "# row 0.\n",
        "# If you want to pick only certain columns you have to\n",
        "# wrap them in a list\n",
        "\n",
        "ds.loc[0:5, ['Ref_Date', 'Type', 'Persons']]"
      ],
      "metadata": {
        "id": "_XiEPiTlp3NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Lists` are another crucial *data type* in `Python` and are wrapped in brackets [ ]. The values are separated by commas."
      ],
      "metadata": {
        "id": "jHp6TT4XsXz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here are more lists\n",
        "\n",
        "['a', 'c', 'f']"
      ],
      "metadata": {
        "id": "vyqCDa-_rgH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_list = [1, 4, 8, 2]\n",
        "a_list"
      ],
      "metadata": {
        "id": "IKh_6mNKroRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Exercise 3\n",
        "\n",
        "Select the 10th to 20th row for *location* and *persons*.\n",
        "\n",
        "> Expand the solution to check your results."
      ],
      "metadata": {
        "id": "XgSXa2w5srnq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DuOcRbkjuXs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "### Solution for exercise 3"
      ],
      "metadata": {
        "id": "jW81cF0buf8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.loc[9:19, ['Location', 'Persons']]"
      ],
      "metadata": {
        "id": "43ZywT5Tsk-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Continuing ..."
      ],
      "metadata": {
        "id": "42nKNX8VuYKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to select a full column you can either use the attribute\n",
        "\n",
        "ds.Location"
      ],
      "metadata": {
        "id": "5rt3WGM0ur2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the column name\n",
        "\n",
        "ds['Location']"
      ],
      "metadata": {
        "id": "tpMMpjZIu45F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the column name in a one-element list\n",
        "\n",
        "ds[['Location']]"
      ],
      "metadata": {
        "id": "-nXYzkTau8gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the .loc method with all rows using :\n",
        "\n",
        "ds.loc[:, 'Location']"
      ],
      "metadata": {
        "id": "vslVtj47vEfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To subset your data set only by position you use method `.iloc`."
      ],
      "metadata": {
        "id": "SX-G6-9TVgUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.iloc[0:5, 0:3]"
      ],
      "metadata": {
        "id": "f9xJJ9_YVnsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can also use negative indices to select from the bottom\n",
        "# for rows or from right for columns.\n",
        "# Note, : select all either rows or columns\n",
        "\n",
        "ds.iloc[:, -2:]"
      ],
      "metadata": {
        "id": "HXqc-id0Vsia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Manipulating data\n",
        "\n",
        "Now, we want to change values in our columns.\n",
        "\n",
        "We want to change values for `Persons` into *negative values* for those rows where `Type` is *Out-migrants*. For doing so, we use method `loc` with adding a condition for the *rows*."
      ],
      "metadata": {
        "id": "4ZaAWwciiIwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.loc[ds['Type'] == 'Out-migrants', 'Persons'] = -ds['Persons']"
      ],
      "metadata": {
        "id": "IO6zHFOUWm4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use describe() to see if it has worked\n",
        "\n",
        "ds.describe()"
      ],
      "metadata": {
        "id": "0owiggUojkdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternatively, we could have used method np.where() like this:\n",
        "\n",
        "# first create a fresh copy of the data set (as we cannot change the same\n",
        "# values twice)\n",
        "ds2 = data_csv.copy()\n",
        "# rename the columns as we have done above\n",
        "ds2.rename(columns={'Value':'Persons', 'INT':'Type'}, inplace=True)\n",
        "\n",
        "# now this is the line where we actually apply the alternative code\n",
        "# np.where(condition, true_value, false_value)\n",
        "ds2['Persons'] = np.where(ds2['Type'] == 'Out-migrants', -ds2['Persons'], ds2['Persons'])\n",
        "\n",
        "# let's check the outcome\n",
        "ds2.describe()"
      ],
      "metadata": {
        "id": "QP9ktn27xOxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting a column/variable\n",
        "\n",
        "Now, we finally want to treat the remaining column `Ref_Date` as it conflates `Year` and `Quarter`.\n",
        "\n",
        "For doing so, we first need to understand *tuples*. A `tuple` is an object that contains *immutable* elements."
      ],
      "metadata": {
        "id": "g8BlM8VerGCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you can construct them using parentheses ()\n",
        "\n",
        "('a', 'b', 'c')"
      ],
      "metadata": {
        "id": "pKctH47jrhUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or not\n",
        "\n",
        "1, 2"
      ],
      "metadata": {
        "id": "9NtsmbNNsgE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `tuples` to assign multiple values in one go. This is called `tuple unpacking` or `multiple assignment`."
      ],
      "metadata": {
        "id": "jp5WhvqGtyyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 3, 4"
      ],
      "metadata": {
        "id": "BbZaS4cMs1Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "MoR-LK0jtAQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we combine tuple unpacking with the `.split()` method, we can achieve our the GeoAnalytics Lab. `.split()` separates a *string* into pieces using the provided separator:"
      ],
      "metadata": {
        "id": "reEYtb7qtJgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here our separator is a space\n",
        "\n",
        "'two words'.split(' ')"
      ],
      "metadata": {
        "id": "A83pUCROtWwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as our Ref_Date variable is a string, we can call str for string methods\n",
        "# and then use the / that separates the year from quarter\n",
        "ds.Ref_Date.str.split('/')"
      ],
      "metadata": {
        "id": "xFuvIKDqRr6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when we now use parameter expand=True it will create sets of two\n",
        "\n",
        "ds.Ref_Date.str.split('/', expand=True)"
      ],
      "metadata": {
        "id": "ppNdl82Mtz0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, let's apply our knowledge of sets to our use case.\n",
        "# note, on the left hand side you need to feed in a list, hence []\n",
        "ds[['Year', 'Quarter']] = ds.Ref_Date.str.split('/', expand=True)"
      ],
      "metadata": {
        "id": "lvELqOWBuGYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you see, that we have created two new columns, bu the old one is still there\n",
        "\n",
        "ds"
      ],
      "metadata": {
        "id": "o8qdkBtcwRLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can, of course, delete it now\n",
        "\n",
        "ds.drop(columns='Ref_Date', inplace=True)"
      ],
      "metadata": {
        "id": "hXkltegsv78a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Exercise 4\n",
        "\n",
        "Select rows for the 2000s years for Quebec only.\n",
        "\n",
        "*Hint: you need to change the variable type with `.astype()`*\n",
        "\n",
        "> To check your result you can expand the solution."
      ],
      "metadata": {
        "id": "bKvpkIAI5H7d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFZR0hcH6YIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Solution for exercise 4"
      ],
      "metadata": {
        "id": "jlohWuMl6Y2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.Year = ds.Year.astype(int)\n",
        "ds.query('Location == \"Quebec\" & Year > 2000')"
      ],
      "metadata": {
        "id": "R8HTDRMy44SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Exercise 5\n",
        "\n",
        "The quarters currently represent months (March, June, September, December). Turn them into quarters 1 to 4 by dividing them by 3.\n",
        "\n",
        "> To check your result expand the solution section."
      ],
      "metadata": {
        "id": "UGESc05-2EPD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGgdHedP2nAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "O0UiKKJn2pxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Solution for exercise 5"
      ],
      "metadata": {
        "id": "vS6BTpGk2oBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.Quarter = (ds.Quarter.astype(int) / 3).astype(int)"
      ],
      "metadata": {
        "id": "JRXgwXTqupnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the result\n",
        "\n",
        "ds"
      ],
      "metadata": {
        "id": "b-kUFu4ovGNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "#### Continuing ..."
      ],
      "metadata": {
        "id": "tNeVHV5J2yt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Grouped summaries\n",
        "\n",
        "The `groupby()` method helps to get grouped summaries:"
      ],
      "metadata": {
        "id": "nqbv8tECzBbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we group the data set ds by Location, then\n",
        "# calculate the mean on Persons column\n",
        "\n",
        "ds.groupby('Location').Persons.mean().round(0)"
      ],
      "metadata": {
        "id": "lgHgvPd3zJ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can group by more than one variable putting the\n",
        "# column names in a list\n",
        "# note, here we then use sum()\n",
        "\n",
        "ds.groupby(['Location', 'Year']).Persons.sum()"
      ],
      "metadata": {
        "id": "Smq6BFPHz5-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying the `unstack()` method on the grouped summary, we can create a pivot table."
      ],
      "metadata": {
        "id": "V-IE5H2C1Nl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_summary = ds.groupby(['Location', 'Year']).Persons.sum()\n",
        "\n",
        "grouped_summary.unstack()"
      ],
      "metadata": {
        "id": "mSHCiPKg0XR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can easily create a line graph from this pivot table using\n",
        "\n",
        "sns.lineplot(grouped_summary.unstack().T)\n",
        "\n",
        "# note, with .T we can transpose the table (i.e. flip x and y axis)"
      ],
      "metadata": {
        "id": "yXghd3Qbm95A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to rectify the overlap in legend and axis, we need to add a bit of\n",
        "# matplotlib code\n",
        "\n",
        "sns.lineplot(grouped_summary.unstack().T)\n",
        "\n",
        "# this moves the graph to the upper left corner relative to the legend\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "# now we get the x axis labels ...\n",
        "labels = plt.gca().get_xticklabels()\n",
        "# make them invisible ...\n",
        "plt.setp(labels, visible = False)\n",
        "# and only show every 10th label\n",
        "plt.setp(labels[::10], visible = True)"
      ],
      "metadata": {
        "id": "CiFzv8_B3QZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Work with your file on your Google Drive\n",
        "\n",
        "You first need to `mount` your drive. For doing so, we need the module `os` and submodule `drive` from `google.colab`."
      ],
      "metadata": {
        "id": "m-iu-SifBT71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlm2bvXPqgGJ"
      },
      "outputs": [],
      "source": [
        "# os helps you to work with operating system related tasks\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getcwd() shows you the current working directory\n",
        "\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "zZZBZxVMqhy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we mount our drive. You will be asked to confirm.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "n76ZmkGrqkhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the working directory to whichever folder you want to work with\n",
        "# I chose 'Colab Notebooks/CAnD3' on my Google Drive\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/CAnD3')\n",
        "\n",
        "# Verify the current working directory\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "acKvV42yCJqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to see the content of your directory, use\n",
        "\n",
        "os.listdir(os.getcwd())"
      ],
      "metadata": {
        "id": "MRoHQg5fDO-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving your data in a file\n",
        "\n",
        "There are lots of `to_*()` methods to export your data to different files."
      ],
      "metadata": {
        "id": "kwPJ8uX4D3wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.to_csv('my_data.csv')\n",
        "ds.to_excel('my_data.xlsx', index=False)"
      ],
      "metadata": {
        "id": "ryIa8-iSDpu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8) Extras"
      ],
      "metadata": {
        "id": "YYAKG-dgFx9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to read/write SPSS files\n",
        "\n",
        "Unfortunately, there seems to be a problem with the `pandas` reader/writer to/from SPSS. Hence, we have to install `pyreadstat` and import it to use its functions."
      ],
      "metadata": {
        "id": "SGvlJw9VF1D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# by using !pip we call the install command in the terminal of the Notebook to\n",
        "# install the missing library from the internet\n",
        "\n",
        "!pip install pyreadstat"
      ],
      "metadata": {
        "id": "XD-sIaxJeu-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have to import the library into our Notebook\n",
        "\n",
        "import pyreadstat"
      ],
      "metadata": {
        "id": "vubXrvJtevdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, we can use read_sav()\n",
        "# Note, I assume you had copied the file into your Google Drive\n",
        "\n",
        "data_sav = pyreadstat.read_sav('migration.sav')\n",
        "\n",
        "# or source it from the repo\n",
        "#data_sav = pyreadstat.read_sav('https://github.com/AGeographer/cand3_2025_python/raw/refs/heads/main/data/migration.sav')"
      ],
      "metadata": {
        "id": "x_Jgk9B8_O8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so, what have we downloaded? Check the type:\n",
        "\n",
        "type(data_sav)"
      ],
      "metadata": {
        "id": "jYStama4Zltt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in the first element we find our data set\n",
        "\n",
        "data_sav[0]"
      ],
      "metadata": {
        "id": "NZi3epycmwL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check if this is a panda data frame\n",
        "\n",
        "# isinstance(data_sav[0], pd.DataFrame)"
      ],
      "metadata": {
        "id": "bivNVs8SY83m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, let's re-assign it, so that we can use the data set properly\n",
        "\n",
        "data_sav = data_sav[0]\n",
        "data_sav"
      ],
      "metadata": {
        "id": "hCGWH3CxYYeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Select columns with conditions\n",
        "\n",
        "You can use method `.filter()` to select columns."
      ],
      "metadata": {
        "id": "ZpMpvntrGKyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feed in a list of variables\n",
        "# you can use this to also sort the columns\n",
        "\n",
        "ds.filter(['Year', 'Location'])"
      ],
      "metadata": {
        "id": "tZ48bPKYHsAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# like= can be use to look for strings that are contained in the\n",
        "# column names, like 'er' here\n",
        "\n",
        "ds.filter(like='er')"
      ],
      "metadata": {
        "id": "vvoh3FF3GsIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# or you can use regular expressions\n",
        "# here all columns that end with 'e'\n",
        "\n",
        "ds.filter(regex='r$')"
      ],
      "metadata": {
        "id": "ctaSkTlDGbgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some more visualizations"
      ],
      "metadata": {
        "id": "83zJOvZLLXws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style='whitegrid')\n",
        "sns.violinplot(data=ds.query(\"Location in ['Ontario', 'Quebec']\"),\n",
        "               y='Location', x='Persons',\n",
        "               hue = 'Quarter',\n",
        "               palette='Set1')"
      ],
      "metadata": {
        "id": "0_l7jijvIUPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=ds.query(\"Year > 2000\"),\n",
        "            y = 'Location', x = 'Persons',\n",
        "            hue = 'Quarter',\n",
        "            dodge=False,\n",
        "            palette='colorblind',\n",
        "            errorbar=None)"
      ],
      "metadata": {
        "id": "aGM_KhIQJa7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}